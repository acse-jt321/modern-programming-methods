{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandboxing & virtual environments\n",
    "\n",
    "Yesterday you learned how to wrap python code up into a package with its own name and version number. There are several situations in which it can be useful to \"[sandbox](https://docs.python.org/3/library/venv.html)\" code into its own space so that other package installations cannot interfere with it, and so that it cannot interfere with them.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Aims: (update with links and further details)\n",
    "\n",
    "- Introduce the basic idea of environment variables\n",
    "- Introduce various virtual environment and container solutions including\n",
    "    - Venv\n",
    "    - Anaconda\n",
    "    - Docker\n",
    "- Explore in further detail how to work with Anaconda\n",
    "\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "<h3>Contact details:</h3>\n",
    "\n",
    " - Dr. Rhodri Nelson\n",
    " - Room 4.88 RSM building\n",
    " - email: rhodri.nelson@imperial.ac.uk\n",
    " - Teams: <code>@Nelson, Rhodri B</code> in <code>Modern Programming Methods 2021</code> or <code>ESE-MSC-2021</code> team channels, or DM me.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviroment variables\n",
    "\n",
    "From Wikipedia (https://en.wikipedia.org/wiki/Environment_variable):\n",
    "\n",
    "_An environment variable is a dynamic-named value that can affect the way running processes will behave on a computer. They are part of the environment in which a process runs. For example, a running process can query the value of the TEMP environment variable to discover a suitable location to store temporary files, or the HOME or USERPROFILE variable to find the directory structure owned by the user running the process._\n",
    "\n",
    "As an example, one important environment variable is the **PATH** variable. To view the value of this variable, on a **Unix** machine you can type\n",
    "```bash\n",
    "echo $PATH\n",
    "```\n",
    "or on a windows machine\n",
    "```bash\n",
    "echo %PATH%\n",
    "```\n",
    "The variable is a list of directory paths. When the user types a command without providing the full path, this list is checked to see whether it contains a path that leads to the command.\n",
    "\n",
    "In summary, the values of environment variables govern how certain as aspects of your environment function, e.g. which executables and libraries will be called/accessed by default, or which options will be used when executing certain commands.\n",
    "\n",
    "### Why do we need a virtual environment?\n",
    "\n",
    "You're also now familiar with the `Python` package manager `pip`. Consider the following two 'dummy' packages and their requirements:\n",
    "\n",
    "- Package **A**, has the following dependencies:\n",
    "    - a, version >= 1.0\n",
    "    - b, version 1.2\n",
    "    - c, version >= 2.2\n",
    "    - d, version >= 5.0\n",
    "- Package **B**, requires:\n",
    "    - a, version >= 1.0\n",
    "    - b, version >= 1.3\n",
    "    - e, version 1.0\n",
    "    - f, version >= 7.0.\n",
    "\n",
    "Reviewing the above, we can see there is a conflict for the dependency b. Clearly, using `pip` to switch between two versions of package `b` every time want to use **A** or **B** is not a good solution. But further, in reality, when working on larger development projects such dependency conflicts may arise for several, or even dozens(!), of packages. Clearly, a better solution is to have both versions of the software installed and an easy way to switch between the appropriate environment variables when using either **A** or **B**. This is where _virtual environments_ come in handy.   \n",
    "\n",
    "A virtual environment is a tool that helps to keep dependencies required by different projects separate by creating isolated python virtual environments for them. This is one of the most important tools that most Python developers use.\n",
    "\n",
    "### When and where to use a virtual environment?\n",
    "\n",
    "By default, every project on your system will use the same directories (defined via environment variables) to store and retrieve site packages (third party libraries). Why does this matter? In the above example of two projects, you have two versions of package `b`. This is a real problem for Python since it can't differentiate between versions in the \"site-packages\" directory. So both v1.2 and v1.3 would reside in the same directory with the same name. This is where virtual environments come into play. To solve this problem, we just need to create two separate virtual environments, one for each project. The great thing about this is that there are no limits to the number of environments you can have since they're just directories containing a few scripts.\n",
    "\n",
    "Along with the above example, we may also want to make use of virtual environments because\n",
    "- Sometimes packages have the same name, but do different things, creating a namespace clash.\n",
    "- Sometimes you need a clean environment to test your package dependencies in order to write your `requirements.txt` file (we will talk more about such files later).\n",
    "\n",
    "### venv\n",
    " \n",
    "Python comes with an [inbuilt library](https://docs.python.org/3/library/venv.html) called `venv` which can be used to create so-called \"virtual environments\". Inside a virtual environment, only the packages and tools you explicitly choose to copy across are available, and only at the version numbers you request. This gives a quick, easy access to a \"clean\" system, be it for testing, or to run mutually incompatible software.\n",
    "\n",
    "To create a new `venv` environment you can run a command like\n",
    "```bash\n",
    "python -m venv foo\n",
    "```\n",
    "or, on systems with both Python 2 and Python 3 available,\n",
    "```bash\n",
    "python3 -m venv foo\n",
    "```\n",
    "\n",
    "This will create a new directory `./foo/` containing the files relevant to that virtual environment. To start the environment on Windows run\n",
    "```bash\n",
    "foo\\Scripts\\activate.bat\n",
    "```\n",
    "or on unix shell like systems\n",
    "```bash\n",
    "source foo/bin/activate\n",
    "```\n",
    "\n",
    "To disable the environment, on windows systems run\n",
    "```bash\n",
    ".\\foo\\Scripts\\deactivate.bat\n",
    "```\n",
    "or, in most unix based shells\n",
    "```bash\n",
    "deactivate\n",
    "```\n",
    "\n",
    "\n",
    "##### Building a `requirements.txt` file using `venv`\n",
    "\n",
    "Switching to a `venv` environment is one way to build up a short list of required packages for a new project. You can start up a blank environment and then try to build and run your code. If a dependency is missing, this should fail with an `ImportError` message, something along the lines of\n",
    "\n",
    "```bash\n",
    "Traceback (most recent call last):\n",
    "   File \"<string>\", line 1, in <module>\n",
    "   File \"/tmp/pip-ukwnrb23-build/setup.py\", line 5, in <module>\n",
    "     from numpy import get_include\n",
    "   ImportError: No module named 'numpy'\n",
    "```\n",
    "\n",
    "Ideally you will then be able to recognise the missing dependency (in this case `numpy`) and fix it by running a command like `pip install numpy`. After repeating as needed to fix any further requirements you can generate a `requirements.txt` compatible list for your Python environment (with the command `pip freeze`, this also lists the currently installed version)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class= exercise>\n",
    "\n",
    "<h4>Exercise : Make a `venv`</h4>\n",
    "<p>Create your own <code>venv</code> environment, giving it a name of your choice. Activate it. Note the difference it makes to your command prompt.</p>\n",
    "\n",
    "<p>Double check the installed package list using <code>pip list</code>. Install a package into the virtual environment (such as <code>matplotlib</code>) using <code>pip</code>. Check that the list of installed packages inside the environment changes.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some other tools (before we talk about Anaconda)\n",
    "\n",
    "- [**virtualenv**](https://virtualenv.pypa.io/en/stable/)\n",
    "\n",
    "This is a popular tool for creating isolated Python environments for Python libraries. **virtualenv** functions by installing various files in a directory (e.g. `env/`), and then modifying the `PATH` environment variable to prefix it with a custom bin directory (e.g. `env/bin/`). An exact copy of the python or python3 binary is placed in this directory, but Python is programmed to look for libraries relative to its path first, in the environment directory. It's not part of Python's standard library, but is officially blessed by the PyPA (Python Packaging Authority). Once activated, you can install packages in the virtual environment using `pip`.\n",
    "\n",
    "- [**docker**](https://www.docker.com/)\n",
    "\n",
    "A virtualenv only encapsulates Python dependencies. A Docker container encapsulates an entire operating system (OS). With a Python virtualenv, you can easily switch between Python versions and dependencies, but you're stuck with your host OS. With a Docker image, you can swap out the entire OS - install and run Python on Ubuntu, Debian, Alpine, even Windows Server Core. There are Docker images out there with every combination of OS and Python versions you can think of, ready to pull down and use on any system with Docker installed.\n",
    "\n",
    "Tools such as Docker are excellent for testing software packages and cross operating system/hardware compatibility. For software development, tools such as Anaconda are generally more convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Anaconda?\n",
    "\n",
    "A open-source distribution of Python that simplifies package management. It comes with applications such as Jupyter Notebook, the Conda environment manager, and Pip for package installation and management.\n",
    "\n",
    "Anaconda also comes with hundreds of Python packages such as matplotlib, NumPy, SymPy and so forth.\n",
    "\n",
    "It eliminates the need to install common applications separately and will (generally) make installing Python on your computer much easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/minions-meme.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_ that a large range of helpful Anaconda tutorials can be found [online](https://docs.anaconda.com/anaconda/navigator/tutorials/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the usage of Anaconda, let us together work through an exercise.\n",
    "\n",
    "For this we will fork, then clone and play around with a dummy package made for this purpose.\n",
    "\n",
    "Go to the address https://github.com/rhodrin/environments_mpm and click on the `fork` button as shown in image below (make sure you're logged into your Github account before doing this):\n",
    "\n",
    "<img src=\"figures/fork.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then clone the forked package (**Make sure you're in an appropriate folder before performing the clone**)- in a terminal type\n",
    "```bash\n",
    "git clone https://github.com/<my github name>/environments_mpm.git\n",
    "```\n",
    "The package can also be cloned via the Visual Studio Code GUI.\n",
    "\n",
    "In the base folder notice the presence of both an `environment.yml` file and a `requirements.txt` file. The `environment.yml` file defines the Anaconda virtual environment we wish to create. If we look at its contents, we see (importantly) `name: envtest`, specifying the name of the environment we're going to create and some dependencies. We'll talk more about them later, but now let us create a 'conda' environment. In the cloned directory type \n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "When that command is complete type\n",
    "```bash\n",
    "conda activate envtest\n",
    "```\n",
    "and following this (making sure that the your terminal has now been modified such that `(envtest)` is appearing) type\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "to install the `envtest` package (recall that the operations performed by this command are governed by the contents of `setup.py`). You can type\n",
    "```bash\n",
    "pip show envtest\n",
    "```\n",
    "to ensure it has installed ok - if present you should see something similar to the following:\n",
    "```bash\n",
    "Name: envtest\n",
    "Version: 0.1.dev2+g13df730\n",
    "Summary: Playing with virtual environments.\n",
    "Home-page: https://github.com/ese-msc-2021/modern-programming-methods\n",
    "Author: Imperial College London\n",
    "Author-email: rhodri.nelson@imperial.ac.uk\n",
    "License: UNKNOWN\n",
    "Location: /data/teaching/msc-ese/misc/environments_mpm_final\n",
    "Requires: \n",
    "Required-by:\n",
    "```\n",
    "Once that is done, let us view the contents of `requirements.txt`. Currently, we see that only one dependency is listed, that of `numpy` (version > 1.16). Lets install this dependency via\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "Now, to check everything is correctly set up, from within the base directory run\n",
    "```bash\n",
    "python scripts/random_number_array.py\n",
    "```\n",
    "You should see output along the lines of\n",
    "```bash\n",
    "[[0.22330655 0.07439368 0.69014812]\n",
    " [0.90354345 0.06734495 0.13096386]\n",
    " [0.22487417 0.6394524  0.41603555]]\n",
    "```\n",
    "(noting that the actual numbers you see will be slightly different since the routine is generating a 3x3 array of random numbers between 0 and 1).\n",
    "\n",
    "Also, lets now look at the result of `echo $PATH` (or `echo %PATH%`) again. Notice the modified value within our environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets add a few further functions, dependencies and scripts to our repository.\n",
    "\n",
    "In the file `envtest/builtins.py`:\n",
    " - add the following two lines right after the existing import\n",
    "```python\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import misc\n",
    "```\n",
    " - Modify `__all__ = ['rand_array']` to `__all__ = ['rand_array', 'smooth_image']`\n",
    " - Add the following function:\n",
    "```python\n",
    "def smooth_image(a, sigma=1):\n",
    "    return gaussian_filter(a, sigma=sigma)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, modify the file `scripts/smooth_image.py` so that it reads (i.e. remove any existing text):\n",
    "```python\n",
    "from envtest import smooth_image\n",
    "\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "image = misc.ascent()\n",
    "sigma = 5\n",
    "\n",
    "smoothed_image = smooth_image(image, sigma)\n",
    "\n",
    "f = plt.figure()\n",
    "f.add_subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "f.add_subplot(1, 2, 2)\n",
    "plt.imshow(smoothed_image)\n",
    "plt.show(block=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, if we try running this script, e.g. `python scripts/smooth_image.py`, we'll see an error of the following form:\n",
    "```bash\n",
    "Traceback (most recent call last):\n",
    "  File \"/data/teaching/msc-ese/misc/environments_mpm/scripts/smooth_image.py\", line 1, in <module>\n",
    "    from envtest import smooth_image\n",
    "  File \"/data/teaching/msc-ese/misc/environments_mpm/envtest/__init__.py\", line 1, in <module>\n",
    "    from .builtins import *\n",
    "  File \"/data/teaching/msc-ese/misc/environments_mpm/envtest/builtins.py\", line 2, in <module>\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "ModuleNotFoundError: No module named 'scipy'\n",
    "```\n",
    "This is of course because we have not yet installed the 'new' required dependencies. These are `scipy` and `matplotlib`, so lets add them to our `requirements.txt` file and install them. That is, modify `requirements.txt` so that is now reads:\n",
    "```\n",
    "numpy>1.16\n",
    "scipy\n",
    "matplotlib\n",
    "```\n",
    "and then type\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "again. (Note that a `pip install scipy` etc would also do the job, but since we want to keep our requirements file up to date it doesn't hurt to use it directly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this, after running the script we should see a plot with the original image on the left and the smoothed image on the right\n",
    "\n",
    "<img src=\"figures/smoothed.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets go through this exercise once more. To `builtins.py` add the following function:\n",
    "```python\n",
    "def my_mat_solve(A, b):\n",
    "    return A.inv()*b\n",
    "```\n",
    "Remember that we need to make this function visible within the package and hence must modify the `__all__ = [...]` line appropriately.\n",
    "\n",
    "Then, lets add a new script to make use of it. In the `scripts` folder create a new file called `solve_matrix_equation.py` and within it paste the following text\n",
    "```python\n",
    "from envtest import my_mat_solve\n",
    "\n",
    "from sympy.matrices import Matrix, MatrixSymbol\n",
    "\n",
    "# Call function to solve the linear equation A*x=b symbolically\n",
    "\n",
    "A = Matrix([[2, 1, 3], [4, 7, 1], [2, 6, 8]])\n",
    "b = Matrix(MatrixSymbol('b', 3, 1))\n",
    "x = my_mat_solve(A, b)\n",
    "\n",
    "print(x)\n",
    "```\n",
    "Our new dependency is `SymPy`. Hence, lets also add that to `requirements.txt` (simply add `sympy` to the end of the file) and then repeat the install command we used previously.\n",
    "\n",
    "To ensure the newly added script runs successfully, upon execution we should see the following output:\n",
    "```bash\n",
    "Matrix([[b[0, 0]/2 + b[1, 0]/10 - b[2, 0]/5], [-3*b[0, 0]/10 + b[1, 0]/10 + b[2, 0]/10], [b[0, 0]/10 - b[1, 0]/10 + b[2, 0]/10]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Finalizing our repository\n",
    "\n",
    "We'll now update our `environment.yml` file and then rebuild our environment to ensure that within our updated environment everything works correctly 'out of the box'.\n",
    "- First, lets check the status of our repository and make sure we add any new files:\n",
    "```bash\n",
    "git status\n",
    "```\n",
    "will return something along the lines of\n",
    "```bash\n",
    "On branch master\n",
    "Your branch is up-to-date with 'origin/master'.\n",
    "\n",
    "Changes not staged for commit:\n",
    "  (use \"git add <file>...\" to update what will be committed)\n",
    "  (use \"git restore <file>...\" to discard changes in working directory)\n",
    "\tmodified:   environment.yml\n",
    "\tmodified:   envtest/builtins.py\n",
    "\tmodified:   requirements.txt\n",
    "\tmodified:   scripts/smooth_image.py\n",
    "\n",
    "Untracked files:\n",
    "  (use \"git add <file>...\" to include in what will be committed)\n",
    "\t.eggs/\n",
    "\tenvtest.egg-info/\n",
    "\tenvtest/__pycache__/\n",
    "\tscripts/solve_matrix_equation.py\n",
    "```\n",
    "The import untracked file we need to add is `scripts/solve_matrix_equation.py` - the others are meta-data **we do not want** under version control. We can add it through\n",
    "```bash\n",
    "git add scripts/solve_matrix_equation.py\n",
    "```\n",
    "- Next, commit the changes we've made via\n",
    "```bash\n",
    "git commit -a -m \"<my commit message>\"\n",
    "```\n",
    "- Then, add a further function of your choice to `builtins.py` and an accompanying script to utilize this function. Ensure that this new function requires _at least_ one new additional dependency (remember to modify `requirements.txt` etc. appropriately). If you're not sure what new package to use, how about a quick [Pandas example](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)? (You'll learn more about Pandas later in this course).\n",
    "- When this is done, and you've confirmed that the new script is working as intended, modify the `environment.yml` and add all new dependencies to it. That is, is should now look along the lines of the following but with **your** additional dependencies also added:\n",
    "```\n",
    "name: envtest\n",
    "channels:\n",
    "  - defaults\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python>=3.6,<3.10\n",
    "  - pip\n",
    "  - numpy>1.16\n",
    "  - scipy\n",
    "  - matplotlib\n",
    "  - sympy\n",
    "```\n",
    "- When this is done, commit all these changes to the repository, remembering to add any new files first - e.g.\n",
    "```bash\n",
    "git add scripts/my_new_script.py\n",
    "```\n",
    "followed by\n",
    "```bash\n",
    "git commit -a -m \"<my commit message>\"\n",
    "```\n",
    "- Push these changes to github\n",
    "```bash\n",
    "git push\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Next, ensure your github repository has updated correctly - you can check this through checking some files in your web-browser.\n",
    "\n",
    "Now, as a test, we'll deactivate and delete our environment and remake it using our updated `environments.yml` file.\n",
    "\n",
    "The required commands are as follows:\n",
    " - `conda deactivate`\n",
    " - `conda remove --name envtest --all`\n",
    " - `conda env create -f environment.yml`\n",
    " \n",
    "Then, once the environment has been created activate it again via `conda activate envtest`. Note that if we now look at `pip list` we will see the full list of required packages along with their dependencies have been installed already.\n",
    "\n",
    "If you happen to run into any issues there's a 'completed' example of the repository available at [here](https://github.com/rhodrin/environments_mpm_final) - **Remember to fork it first if you want to play around and edit it**.\n",
    "\n",
    "(**NOTE**: In practice we'd generally create a new environment with a different name to test everything is working, but since this is a 'dummy' package and to avoid 'clutter' we'll do it this way for the time being)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final note, think about why is it important to have both `environment.yml` and `requirements.txt` files.\n",
    "\n",
    "- The `environment.yml` was used only when creating our environment. Remember it was useful to have the `requirements.txt` file to install the required packages when developing our environment. (Although we could have also continuously updated our environment file and then updated our environment via `conda env update -f environment.yml`).\n",
    "- In any case, we generally want both for people making use of our package who are not using `Anaconda`. As we saw earlier, we could use such a requirements file in `venv`.\n",
    "- Additionally, what if we want some packages to not be installed automatically when creating our environment? For various reasons, we may with to have an, e.g. `requirements-optional.txt` file present (generally the packages listed in `environment.yml` and `requirements.txt` should be in sync unless there's a good reason for them not to be). Any such optional requirements can be installed via the `pip install -r ... .txt` command once again.\n",
    "- There are other `conda` package vs `pip` package reasons also, but that's something that may be raised later in the course when necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
